{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNW7zGSnj2cENB2ET+tJoee"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "wZkMiPQZDq5n",
        "outputId": "c26023e1-118f-4c0e-d085-d1a9885d676d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'rouge_score'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7f8176ae3337>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# summary_utils.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrouge_score\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrouge_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbleu_score\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msentence_bleu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSmoothingFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rouge_score'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# summary_utils.py\n",
        "\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from datasets import Dataset\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "### SummaryEvalutator\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "\n",
        "class SummaryEvaluator:\n",
        "    \"\"\"\n",
        "    A class for evaluating text summarization models using ROUGE and BLEU metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, rouge_metrics=['rouge1', 'rouge2', 'rougeL'], use_stemmer=True):\n",
        "        \"\"\"\n",
        "        Initializes the RougeBleuEvaluator.\n",
        "\n",
        "        Args:\n",
        "            rouge_metrics (list): List of ROUGE metrics to calculate (e.g., ['rouge1', 'rouge2', 'rougeL']).\n",
        "            use_stemmer (bool): Whether to use stemming for calculating ROUGE scores.\n",
        "        \"\"\"\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(rouge_metrics, use_stemmer=use_stemmer)\n",
        "        self.smoothing_function = SmoothingFunction().method4  # Choose a smoothing method\n",
        "        self.rouge_metrics = rouge_metrics\n",
        "\n",
        "    def calculate_rouge(self, reference_summaries, generated_summaries):\n",
        "        \"\"\"\n",
        "        Calculates ROUGE scores.\n",
        "        \"\"\"\n",
        "        if isinstance(reference_summaries, Dataset):\n",
        "            reference_summaries = reference_summaries[\"summary\"]\n",
        "\n",
        "        rouge_scores = []\n",
        "        for ref_summary, gen_summary in zip(reference_summaries, generated_summaries):\n",
        "            scores = self.rouge_scorer.score(ref_summary, gen_summary)\n",
        "            rouge_scores.append(scores)\n",
        "\n",
        "        avg_rouge_scores = {\n",
        "            metric: sum(score[metric].fmeasure for score in rouge_scores) / len(rouge_scores)\n",
        "            for metric in self.rouge_metrics\n",
        "        }\n",
        "\n",
        "        return avg_rouge_scores\n",
        "\n",
        "    def calculate_bleu(self, reference_summaries, generated_summaries):\n",
        "        \"\"\"\n",
        "        Calculates BLEU scores.\n",
        "        \"\"\"\n",
        "\n",
        "        if isinstance(reference_summaries, Dataset):\n",
        "            reference_summaries = reference_summaries[\"summary\"]\n",
        "\n",
        "        bleu_scores = []\n",
        "        for ref_summary, gen_summary in zip(reference_summaries, generated_summaries):\n",
        "            # Tokenize summaries into words or subwords (depends on your model)\n",
        "            reference_tokens = ref_summary.split()\n",
        "            generated_tokens = gen_summary.split()\n",
        "            score = sentence_bleu([reference_tokens], generated_tokens, smoothing_function=self.smoothing_function)\n",
        "            bleu_scores.append(score)\n",
        "\n",
        "        avg_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
        "\n",
        "        return avg_bleu_score\n",
        "\n",
        "    def evaluate(self, reference_summaries, generated_summaries):\n",
        "        \"\"\"\n",
        "        Calculates and prints both ROUGE and BLEU scores.\n",
        "        \"\"\"\n",
        "        avg_rouge_scores = self.calculate_rouge(reference_summaries, generated_summaries)\n",
        "        avg_bleu_score = self.calculate_bleu(reference_summaries, generated_summaries)\n",
        "\n",
        "        print(\"Average ROUGE scores:\", avg_rouge_scores)\n",
        "        print(\"Average BLEU score:\", avg_bleu_score)\n",
        "\n",
        "        return avg_rouge_scores, avg_bleu_score\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "### DatasetManager\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "\n",
        "class DatasetManager:\n",
        "    \"\"\"\n",
        "    A class for loading and sampling datasets from the Hugging Face Datasets library.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset_name=\"xsum\", sample_size=1, seed=42):\n",
        "        \"\"\"\n",
        "        Initializes the DatasetManager.\n",
        "\n",
        "        Args:\n",
        "            dataset_name (str): Name of the dataset to load (default is \"xsum\").\n",
        "            sample_size (int): Number of examples to sample (default is 1).\n",
        "            seed (int): Seed for shuffling the dataset (default is 42).\n",
        "        \"\"\"\n",
        "        self.dataset_name = dataset_name\n",
        "        self.sample_size = sample_size\n",
        "        self.seed = seed\n",
        "        self._dataset = None  # Initialize dataset attribute\n",
        "\n",
        "    def util_load_dataset(self):\n",
        "        \"\"\"\n",
        "        Loads the full dataset and stores it as an attribute.\n",
        "        \"\"\"\n",
        "        if self._dataset is None:\n",
        "            self._dataset = load_dataset(self.dataset_name)\n",
        "        return self._dataset\n",
        "\n",
        "    def load_sampled_dataset(self):\n",
        "        \"\"\"\n",
        "        Loads and samples a subset of the dataset.\n",
        "        \"\"\"\n",
        "        dataset = self.util_load_dataset()  # Ensure the full dataset is loaded\n",
        "        return dataset['train'].shuffle(seed=self.seed).select(range(self.sample_size))\n",
        "\n",
        "    # Additional methods for convenience (optional)\n",
        "    def get_dataset_name(self):\n",
        "        \"\"\"\n",
        "        Returns the name of the loaded dataset.\n",
        "        \"\"\"\n",
        "        return self.dataset_name\n",
        "\n",
        "    def get_sample_size(self):\n",
        "        \"\"\"\n",
        "        Returns the current sample size.\n",
        "        \"\"\"\n",
        "        return self.sample_size\n",
        "\n",
        "    def set_sample_size(self, new_size):\n",
        "        \"\"\"\n",
        "        Updates the sample size.\n",
        "        \"\"\"\n",
        "        self.sample_size = new_size\n",
        "\n",
        "    def get_seed(self):\n",
        "        \"\"\"\n",
        "        Returns the current seed.\n",
        "        \"\"\"\n",
        "        return self.seed\n",
        "\n",
        "    def set_seed(self, new_seed):\n",
        "        \"\"\"\n",
        "        Updates the seed.\n",
        "        \"\"\"\n",
        "        self.seed = new_seed\n",
        "\n",
        "    def explore_dataset(self):\n",
        "        \"\"\"\n",
        "        Explores the dataset and prints the first few rows.\n",
        "        \"\"\"\n",
        "        dataset = self.load_dataset()  # Ensure the full dataset is loaded\n",
        "\n",
        "        train_df = pd.DataFrame(dataset['train'])\n",
        "        validation_df = pd.DataFrame(dataset['validation'])\n",
        "        test_df = pd.DataFrame(dataset['test'])\n",
        "\n",
        "        print(\"Number of Training Examples:\", len(train_df))\n",
        "        print(\"Number of Validation Examples:\", len(validation_df))\n",
        "        print(\"Number of Test Examples:\", len(test_df))\n",
        "\n",
        "    def print_train_dataset_head(self):\n",
        "        \"\"\"\n",
        "        Prints information about the loaded dataset.\n",
        "        \"\"\"\n",
        "        dataset = self.load_dataset()  # Ensure the full dataset is loaded\n",
        "        train_df = pd.DataFrame(dataset['train'])\n",
        "        print(train_df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\")) # Show first 5 rows of the training set in a markdown table\n",
        "\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "### SummaryModel\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "\n",
        "class SummaryModel:\n",
        "    \"\"\"\n",
        "    A class for evaluating and generating summaries using a T5 model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, tokenizer, max_position_embeddings=512, max_length=150, min_length=30,\n",
        "                 length_penalty=2.0, num_beams=4, early_stopping=True):\n",
        "        \"\"\"\n",
        "        Initializes the SummarizationModel.\n",
        "\n",
        "        Args:\n",
        "            model: The T5 model for summarization (e.g., T5ForConditionalGeneration).\n",
        "            tokenizer: The T5 tokenizer for preprocessing.\n",
        "            max_length (int): Maximum length of the generated summary.\n",
        "            min_length (int): Minimum length of the generated summary.\n",
        "            length_penalty (float): Penalty for summary length.\n",
        "            num_beams (int): Number of beams for beam search decoding.\n",
        "            early_stopping (bool): Whether to use early stopping in beam search.\n",
        "        \"\"\"\n",
        "        self.summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
        "        self.max_length = max_length\n",
        "        self.min_length = min_length\n",
        "        self.length_penalty = length_penalty\n",
        "        self.num_beams = num_beams\n",
        "        self.early_stopping = early_stopping\n",
        "        self.max_position_embeddings = max_position_embeddings\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "\n",
        "    def generate_summaries(self, dataset):\n",
        "        \"\"\"\n",
        "        Generates summaries for a given dataset.\n",
        "\n",
        "        Args:\n",
        "            dataset (Dataset): The dataset containing documents to summarize.\n",
        "\n",
        "        Returns:\n",
        "            list: A list of generated summaries.\n",
        "        \"\"\"\n",
        "        generated_summaries = []\n",
        "        for example in dataset:\n",
        "            document = example['document']\n",
        "            if len(self.tokenizer.encode(document)) > self.max_position_embeddings:\n",
        "                document = self.tokenizer.decode(self.tokenizer.encode(document)[:self.max_position_embeddings-1]) # -1 to account for [SEP] token\n",
        "\n",
        "            summary = self.summarizer(\n",
        "                document,\n",
        "                max_length=self.max_length,\n",
        "                min_length=self.min_length,\n",
        "                length_penalty=self.length_penalty,\n",
        "                num_beams=self.num_beams,\n",
        "                early_stopping=self.early_stopping\n",
        "            )[0]['summary_text']\n",
        "            generated_summaries.append(summary)\n",
        "\n",
        "        return generated_summaries\n"
      ]
    }
  ]
}