{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4iADXql+8eJC5Q1Fz+uQI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sleighton2022/datasci266-final-project/blob/main/summary_utils.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZkMiPQZDq5n",
        "outputId": "fcf2c0c8-6a93-4e62-869d-42db9ac7d04a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing summary_utils.py\n"
          ]
        }
      ],
      "source": [
        "# summary_utils.py\n",
        "\n",
        "%%writefile summary_utils.py\n",
        "\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from datasets import Dataset\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "### SummaryEvalutator\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "\n",
        "class SummaryEvaluator:\n",
        "    \"\"\"\n",
        "    A class for evaluating text summarization models using ROUGE and BLEU metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, rouge_metrics=['rouge1', 'rouge2', 'rougeL'], use_stemmer=True):\n",
        "        \"\"\"\n",
        "        Initializes the RougeBleuEvaluator.\n",
        "\n",
        "        Args:\n",
        "            rouge_metrics (list): List of ROUGE metrics to calculate (e.g., ['rouge1', 'rouge2', 'rougeL']).\n",
        "            use_stemmer (bool): Whether to use stemming for calculating ROUGE scores.\n",
        "        \"\"\"\n",
        "        self.rouge_scorer = rouge_scorer.RougeScorer(rouge_metrics, use_stemmer=use_stemmer)\n",
        "        self.smoothing_function = SmoothingFunction().method4  # Choose a smoothing method\n",
        "        self.rouge_metrics = rouge_metrics\n",
        "\n",
        "    def calculate_rouge(self, reference_summaries, generated_summaries):\n",
        "        \"\"\"\n",
        "        Calculates ROUGE scores.\n",
        "        \"\"\"\n",
        "        if isinstance(reference_summaries, Dataset):\n",
        "            reference_summaries = reference_summaries[\"summary\"]\n",
        "\n",
        "        rouge_scores = []\n",
        "        for ref_summary, gen_summary in zip(reference_summaries, generated_summaries):\n",
        "            scores = self.rouge_scorer.score(ref_summary, gen_summary)\n",
        "            rouge_scores.append(scores)\n",
        "\n",
        "        avg_rouge_scores = {\n",
        "            metric: sum(score[metric].fmeasure for score in rouge_scores) / len(rouge_scores)\n",
        "            for metric in self.rouge_metrics\n",
        "        }\n",
        "\n",
        "        return avg_rouge_scores\n",
        "\n",
        "    def calculate_bleu(self, reference_summaries, generated_summaries):\n",
        "        \"\"\"\n",
        "        Calculates BLEU scores.\n",
        "        \"\"\"\n",
        "\n",
        "        if isinstance(reference_summaries, Dataset):\n",
        "            reference_summaries = reference_summaries[\"summary\"]\n",
        "\n",
        "        bleu_scores = []\n",
        "        for ref_summary, gen_summary in zip(reference_summaries, generated_summaries):\n",
        "            # Tokenize summaries into words or subwords (depends on your model)\n",
        "            reference_tokens = ref_summary.split()\n",
        "            generated_tokens = gen_summary.split()\n",
        "            score = sentence_bleu([reference_tokens], generated_tokens, smoothing_function=self.smoothing_function)\n",
        "            bleu_scores.append(score)\n",
        "\n",
        "        avg_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
        "\n",
        "        return avg_bleu_score\n",
        "\n",
        "    def evaluate(self, reference_summaries, generated_summaries):\n",
        "        \"\"\"\n",
        "        Calculates and prints both ROUGE and BLEU scores.\n",
        "        \"\"\"\n",
        "        avg_rouge_scores = self.calculate_rouge(reference_summaries, generated_summaries)\n",
        "        avg_bleu_score = self.calculate_bleu(reference_summaries, generated_summaries)\n",
        "\n",
        "        print(\"Average ROUGE scores:\", avg_rouge_scores)\n",
        "        print(\"Average BLEU score:\", avg_bleu_score)\n",
        "\n",
        "        return avg_rouge_scores, avg_bleu_score\n",
        "\n",
        "\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "### DatasetManager\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "\n",
        "class DatasetManager:\n",
        "    \"\"\"\n",
        "    A class for loading and sampling datasets from the Hugging Face Datasets library.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset_name=\"xsum\", sample_size=1, seed=42):\n",
        "        \"\"\"\n",
        "        Initializes the DatasetManager.\n",
        "\n",
        "        Args:\n",
        "            dataset_name (str): Name of the dataset to load (default is \"xsum\").\n",
        "            sample_size (int): Number of examples to sample (default is 1).\n",
        "            seed (int): Seed for shuffling the dataset (default is 42).\n",
        "        \"\"\"\n",
        "        self.dataset_name = dataset_name\n",
        "        self.sample_size = sample_size\n",
        "        self.seed = seed\n",
        "        self._dataset = None  # Initialize dataset attribute\n",
        "\n",
        "    def util_load_dataset(self):\n",
        "        \"\"\"\n",
        "        Loads the full dataset and stores it as an attribute.\n",
        "        \"\"\"\n",
        "        if self._dataset is None:\n",
        "            self._dataset = load_dataset(self.dataset_name)\n",
        "        return self._dataset\n",
        "\n",
        "    def load_sampled_dataset(self):\n",
        "        \"\"\"\n",
        "        Loads and samples a subset of the dataset.\n",
        "        \"\"\"\n",
        "        dataset = self.util_load_dataset()  # Ensure the full dataset is loaded\n",
        "        return dataset['train'].shuffle(seed=self.seed).select(range(self.sample_size))\n",
        "\n",
        "    # Additional methods for convenience (optional)\n",
        "    def get_dataset_name(self):\n",
        "        \"\"\"\n",
        "        Returns the name of the loaded dataset.\n",
        "        \"\"\"\n",
        "        return self.dataset_name\n",
        "\n",
        "    def get_sample_size(self):\n",
        "        \"\"\"\n",
        "        Returns the current sample size.\n",
        "        \"\"\"\n",
        "        return self.sample_size\n",
        "\n",
        "    def set_sample_size(self, new_size):\n",
        "        \"\"\"\n",
        "        Updates the sample size.\n",
        "        \"\"\"\n",
        "        self.sample_size = new_size\n",
        "\n",
        "    def get_seed(self):\n",
        "        \"\"\"\n",
        "        Returns the current seed.\n",
        "        \"\"\"\n",
        "        return self.seed\n",
        "\n",
        "    def set_seed(self, new_seed):\n",
        "        \"\"\"\n",
        "        Updates the seed.\n",
        "        \"\"\"\n",
        "        self.seed = new_seed\n",
        "\n",
        "    def explore_dataset(self):\n",
        "        \"\"\"\n",
        "        Explores the dataset and prints the first few rows.\n",
        "        \"\"\"\n",
        "        dataset = self.load_dataset()  # Ensure the full dataset is loaded\n",
        "\n",
        "        train_df = pd.DataFrame(dataset['train'])\n",
        "        validation_df = pd.DataFrame(dataset['validation'])\n",
        "        test_df = pd.DataFrame(dataset['test'])\n",
        "\n",
        "        print(\"Number of Training Examples:\", len(train_df))\n",
        "        print(\"Number of Validation Examples:\", len(validation_df))\n",
        "        print(\"Number of Test Examples:\", len(test_df))\n",
        "\n",
        "    def print_train_dataset_head(self):\n",
        "        \"\"\"\n",
        "        Prints information about the loaded dataset.\n",
        "        \"\"\"\n",
        "        dataset = self.load_dataset()  # Ensure the full dataset is loaded\n",
        "        train_df = pd.DataFrame(dataset['train'])\n",
        "        print(train_df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\")) # Show first 5 rows of the training set in a markdown table\n",
        "\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "### SummaryModel\n",
        "#############################################################################\n",
        "#############################################################################\n",
        "\n",
        "class SummaryModel:\n",
        "    \"\"\"\n",
        "    A class for evaluating and generating summaries using a T5 model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, tokenizer, max_position_embeddings=512, max_length=150, min_length=30,\n",
        "                 length_penalty=2.0, num_beams=4, early_stopping=True):\n",
        "        \"\"\"\n",
        "        Initializes the SummarizationModel.\n",
        "\n",
        "        Args:\n",
        "            model: The T5 model for summarization (e.g., T5ForConditionalGeneration).\n",
        "            tokenizer: The T5 tokenizer for preprocessing.\n",
        "            max_length (int): Maximum length of the generated summary.\n",
        "            min_length (int): Minimum length of the generated summary.\n",
        "            length_penalty (float): Penalty for summary length.\n",
        "            num_beams (int): Number of beams for beam search decoding.\n",
        "            early_stopping (bool): Whether to use early stopping in beam search.\n",
        "        \"\"\"\n",
        "        self.summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
        "        self.max_length = max_length\n",
        "        self.min_length = min_length\n",
        "        self.length_penalty = length_penalty\n",
        "        self.num_beams = num_beams\n",
        "        self.early_stopping = early_stopping\n",
        "        self.max_position_embeddings = max_position_embeddings\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "\n",
        "    def generate_summaries(self, dataset):\n",
        "        \"\"\"\n",
        "        Generates summaries for a given dataset.\n",
        "\n",
        "        Args:\n",
        "            dataset (Dataset): The dataset containing documents to summarize.\n",
        "\n",
        "        Returns:\n",
        "            list: A list of generated summaries.\n",
        "        \"\"\"\n",
        "        generated_summaries = []\n",
        "        for example in dataset:\n",
        "            document = example['document']\n",
        "            if len(self.tokenizer.encode(document)) > self.max_position_embeddings:\n",
        "                document = self.tokenizer.decode(self.tokenizer.encode(document)[:self.max_position_embeddings-1]) # -1 to account for [SEP] token\n",
        "\n",
        "            summary = self.summarizer(\n",
        "                document,\n",
        "                max_length=self.max_length,\n",
        "                min_length=self.min_length,\n",
        "                length_penalty=self.length_penalty,\n",
        "                num_beams=self.num_beams,\n",
        "                early_stopping=self.early_stopping\n",
        "            )[0]['summary_text']\n",
        "            generated_summaries.append(summary)\n",
        "\n",
        "        return generated_summaries\n"
      ]
    }
  ]
}